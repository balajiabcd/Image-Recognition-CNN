{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CNN flower recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balajiabcd/Image-Recognition-CNN/blob/main/CNN_flower_recognition_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE3UeJ8n1D4f"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvq6Y-kl1D4h"
      },
      "source": [
        "### Importning Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5kXnzaz1D4i"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqojieg31D4j"
      },
      "source": [
        "### Image Preprocessing for train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5zdYQEs1D4k",
        "outputId": "8a2b187c-e9fa-41b0-bad1-19e494875c21"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3428 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_iKX67R1D4l"
      },
      "source": [
        "### Image Preprocessing for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mNSz5uL1D4m",
        "outputId": "1372529d-0366-4f69-c3af-8e76f11e3262"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = train_datagen.flow_from_directory(\n",
        "        'test',\n",
        "        target_size=(64,64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 889 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEsnGCb91D4n"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gDoqWM81D4n"
      },
      "source": [
        "### Initializing CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcz75udG1D4o"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJV5Zua71D4p"
      },
      "source": [
        "### First layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGxcu2zX1D4p"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxJTlpmI1D4q"
      },
      "source": [
        "### Second layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR36LHEa1D4q"
      },
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1V3krIu1D4q"
      },
      "source": [
        "### Flatening and Full connection and Output layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bts01FHr1D4r"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=5, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGNSktqw1D4r"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-mzs7O61D4r",
        "outputId": "0e769b92-15ab-4a3d-a7c6-cf7cb7062117"
      },
      "source": [
        "cnn.compile(optimizer = 'SGD', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "cnn.fit(x = train_set, validation_data = test_set, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "108/108 [==============================] - 51s 467ms/step - loss: 1.6040 - accuracy: 0.2544 - val_loss: 1.6206 - val_accuracy: 0.1260\n",
            "Epoch 2/25\n",
            "108/108 [==============================] - 23s 211ms/step - loss: 1.5950 - accuracy: 0.2742 - val_loss: 1.6376 - val_accuracy: 0.1260\n",
            "Epoch 3/25\n",
            "108/108 [==============================] - 23s 211ms/step - loss: 1.5919 - accuracy: 0.2742 - val_loss: 1.6474 - val_accuracy: 0.1260\n",
            "Epoch 4/25\n",
            "108/108 [==============================] - 25s 228ms/step - loss: 1.5905 - accuracy: 0.2742 - val_loss: 1.6551 - val_accuracy: 0.1260\n",
            "Epoch 5/25\n",
            "108/108 [==============================] - 24s 219ms/step - loss: 1.5897 - accuracy: 0.2742 - val_loss: 1.6606 - val_accuracy: 0.1260\n",
            "Epoch 6/25\n",
            "108/108 [==============================] - 31s 286ms/step - loss: 1.5887 - accuracy: 0.2742 - val_loss: 1.6606 - val_accuracy: 0.1260\n",
            "Epoch 7/25\n",
            "108/108 [==============================] - 28s 262ms/step - loss: 1.5879 - accuracy: 0.2742 - val_loss: 1.6592 - val_accuracy: 0.1260\n",
            "Epoch 8/25\n",
            "108/108 [==============================] - 22s 202ms/step - loss: 1.5868 - accuracy: 0.2742 - val_loss: 1.6592 - val_accuracy: 0.1260\n",
            "Epoch 9/25\n",
            "108/108 [==============================] - 23s 211ms/step - loss: 1.5857 - accuracy: 0.2742 - val_loss: 1.6576 - val_accuracy: 0.1260\n",
            "Epoch 10/25\n",
            "108/108 [==============================] - 22s 202ms/step - loss: 1.5844 - accuracy: 0.2742 - val_loss: 1.6562 - val_accuracy: 0.1260\n",
            "Epoch 11/25\n",
            "108/108 [==============================] - 22s 205ms/step - loss: 1.5825 - accuracy: 0.2742 - val_loss: 1.6520 - val_accuracy: 0.1260\n",
            "Epoch 12/25\n",
            "108/108 [==============================] - 22s 203ms/step - loss: 1.5795 - accuracy: 0.2742 - val_loss: 1.6498 - val_accuracy: 0.1260\n",
            "Epoch 13/25\n",
            "108/108 [==============================] - 22s 203ms/step - loss: 1.5755 - accuracy: 0.2742 - val_loss: 1.6428 - val_accuracy: 0.1260\n",
            "Epoch 14/25\n",
            "108/108 [==============================] - 22s 208ms/step - loss: 1.5697 - accuracy: 0.2742 - val_loss: 1.6322 - val_accuracy: 0.1260\n",
            "Epoch 15/25\n",
            "108/108 [==============================] - 22s 205ms/step - loss: 1.5615 - accuracy: 0.2742 - val_loss: 1.6198 - val_accuracy: 0.1260\n",
            "Epoch 16/25\n",
            "108/108 [==============================] - 23s 208ms/step - loss: 1.5497 - accuracy: 0.2754 - val_loss: 1.6061 - val_accuracy: 0.1305\n",
            "Epoch 17/25\n",
            "108/108 [==============================] - 22s 205ms/step - loss: 1.5370 - accuracy: 0.3019 - val_loss: 1.5949 - val_accuracy: 0.1957\n",
            "Epoch 18/25\n",
            "108/108 [==============================] - 22s 205ms/step - loss: 1.5229 - accuracy: 0.3226 - val_loss: 1.5470 - val_accuracy: 0.2745\n",
            "Epoch 19/25\n",
            "108/108 [==============================] - 22s 206ms/step - loss: 1.5101 - accuracy: 0.3337 - val_loss: 1.5390 - val_accuracy: 0.2700\n",
            "Epoch 20/25\n",
            "108/108 [==============================] - 23s 210ms/step - loss: 1.4986 - accuracy: 0.3288 - val_loss: 1.6114 - val_accuracy: 0.2283\n",
            "Epoch 21/25\n",
            "108/108 [==============================] - 22s 206ms/step - loss: 1.4862 - accuracy: 0.3288 - val_loss: 1.5049 - val_accuracy: 0.2913\n",
            "Epoch 22/25\n",
            "108/108 [==============================] - 22s 207ms/step - loss: 1.4770 - accuracy: 0.3305 - val_loss: 1.4917 - val_accuracy: 0.2947\n",
            "Epoch 23/25\n",
            "108/108 [==============================] - 22s 207ms/step - loss: 1.4642 - accuracy: 0.3422 - val_loss: 1.5679 - val_accuracy: 0.2666\n",
            "Epoch 24/25\n",
            "108/108 [==============================] - 22s 205ms/step - loss: 1.4581 - accuracy: 0.3396 - val_loss: 1.5242 - val_accuracy: 0.2790\n",
            "Epoch 25/25\n",
            "108/108 [==============================] - 22s 200ms/step - loss: 1.4496 - accuracy: 0.3340 - val_loss: 1.5827 - val_accuracy: 0.2531\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1877900b100>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuQg_jUF1D4s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}